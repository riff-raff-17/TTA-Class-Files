{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e1971b7",
   "metadata": {},
   "source": [
    "### MountainCar-v0 with Gymnasium + Stable-Baselines3 (Step-by-Step)\n",
    "\n",
    "In this notebook you'll:\n",
    "\n",
    "- Inspect the MountainCar-v0 environment (state, actions, rewards)\n",
    "\n",
    "- Run a random policy to build intuition\n",
    "\n",
    "- Train a DQN agent with Stable-Baselines3\n",
    "\n",
    "- Evaluate, record a short video, and plot learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da21c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install \"gymnasium[other,classic_control]\" stable-baselines3 tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9369d290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import stable_baselines3 as sb3\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
    "\n",
    "print(\"Gymnasium:\", gym.__version__)\n",
    "print(\"Stable-Baselines3:\", sb3.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d50b779",
   "metadata": {},
   "source": [
    "### Meet MountainCar-v0\n",
    "\n",
    "State (observation): [position, velocity] (shape: 2)\n",
    "\n",
    "Actions: {0: push left, 1: no push, 2: push right}\n",
    "\n",
    "Goal: Drive the underpowered car up the right hill (position ≥ 0.5).\n",
    "\n",
    "Reward: −1 per step until the goal is reached (shorter episodes = better).\n",
    "\n",
    "Episode ends: goal reached or after 200 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2d8543",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"MountainCar-v0\")\n",
    "print(\"Observation space: \", env.observation_space)\n",
    "print(\"Action space: \", env.action_space)\n",
    "\n",
    "obs, info = env.reset(seed=42)\n",
    "print(\"Initial observation:\", obs, \" | info:\", info)\n",
    "print(\"Sample action:\", env.action_space.sample())\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438702dd",
   "metadata": {},
   "source": [
    "**Roll out one random episode**\n",
    "\n",
    "This helps you see how the state evolves and why naive actions fail.\n",
    "We'll track the car's position over time and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f916367",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"MountainCar-v0\")\n",
    "positions = []\n",
    "rewards = []\n",
    "obs, info = env.reset(seed=123)\n",
    "\n",
    "done = False\n",
    "total_r = 0\n",
    "while not done:\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    positions.append(obs[0])\n",
    "    rewards.append(reward)\n",
    "    total_r += reward\n",
    "\n",
    "env.close()\n",
    "\n",
    "print(\"Episode length: \", len(rewards), \" | Total reward:\", total_r)\n",
    "\n",
    "# Plot position over steps\n",
    "plt.figure()\n",
    "plt.plot(positions)\n",
    "plt.title(\"Random driving\")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Position\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94167f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log dir: ./mountaincar_logs\n",
      "Video dir: ./mountaincar_videos\n"
     ]
    }
   ],
   "source": [
    "from gymnasium.wrappers import RecordVideo\n",
    "\n",
    "log_dir = \"./mountaincar_logs\"\n",
    "video_dir = \"./mountaincar_videos\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "os.makedirs(video_dir, exist_ok=True)\n",
    "\n",
    "# Monitored env for training stats\n",
    "def make_env(seed=0):\n",
    "    e = gym.make(\"MountainCar-v0\", render_mode=None)\n",
    "    e = Monitor(e, filename=os.path.join(log_dir, \"monitor.csv\"))\n",
    "    return e\n",
    "\n",
    "# A seperate env only for video to avoid slowing down training\n",
    "def make_video_env(seed=123):\n",
    "    e = gym.make(\"MountainCar-v0\", render_mode=\"rgb_array\")\n",
    "    e = RecordVideo(e, video_folder=video_dir, episode_trigger=lambda ep : True)\n",
    "    return e\n",
    "\n",
    "print(\"Log dir:\", log_dir)\n",
    "print(\"Video dir:\", video_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5495d463",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_video = gym.make(\"MountainCar-v0\", render_mode=\"rgb_array\")\n",
    "env_video = RecordVideo(env_video, video_folder=video_dir, \n",
    "                        episode_trigger=lambda ep: True, name_prefix=\"test_run\")\n",
    "\n",
    "obs, info = env_video.reset(seed=2)\n",
    "done = False\n",
    "while not done:\n",
    "    action = env_video.action_space.sample()\n",
    "    obs, reward, terminated, truncated, info = env_video.step(action)\n",
    "    done = terminated or truncated\n",
    "\n",
    "env_video.close()\n",
    "print(\"Sample video saved to: \", os.path.abspath(video_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593d0833",
   "metadata": {},
   "source": [
    "A tiny callback to save the best model\n",
    "\n",
    "We'll compute a simple moving mean of rewards using Monitor logs and save the best-performing checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b47f17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveBest(BaseCallback):\n",
    "    def __init__(self, check_freq, log_dir, verbose=1):\n",
    "        super().__init__(verbose)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
