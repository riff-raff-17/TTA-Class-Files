{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "021e77a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval‑Augmented ChatCLI (type 'quit' to exit)\n",
      "\n",
      "[Time: 7.10s]\n",
      "Bot: There are so many interesting topics we could discuss. Here are some ideas:\n",
      "\n",
      "1. **Hobbies**: What do you enjoy doing in your free time? Do you have any new hobbies or interests that you're excited about?\n",
      "2. **Travel**: Have you traveled to any new places recently or have any upcoming trips planned? Where would you like to travel to someday?\n",
      "3. **Technology**: Are there any new gadgets or technologies that you're interested in learning more about? For example, AI, space exploration, or virtual reality?\n",
      "4. **Books/Movies/TV**: What have you read, watched, or listened to lately that you'd recommend?\n",
      "5. **Goals and aspirations**: Is there something you've been wanting to achieve or work towards? I'm here to listen and offer support if you need it.\n",
      "6. **Current events**: Is there a news story or issue that's been on your mind? We could discuss it and explore different perspectives.\n",
      "7. **Learning something new**: Are there any subjects or topics you've always wanted to learn more about but haven't had the chance yet?\n",
      "8. **Personal growth**: What are some things you're working on to improve yourself or your well-being?\n",
      "\n",
      "Or, if you're feeling adventurous, we could play a game like:\n",
      "\n",
      "* \"Would you rather...\" (e.g., would you rather have the ability to fly or be invisible?)\n",
      "* \"Two truths and a lie\" (where I tell you three statements about myself, and you try to guess which one is not true)\n",
      "* Or even just have a fun conversation starter, like \"If you could have any superpower for a day, what would it be?\"\n",
      "\n",
      "What sounds interesting to you? \n",
      "\n",
      "[Time: 3.41s]\n",
      "Bot: I'll come up with three statements about myself (or rather, our conversation). Two of them will be true, and one will be a fabrication. Your task is to guess which one is the lie.\n",
      "\n",
      "Here are my three statements:\n",
      "\n",
      "1. **Hello World**: I've been trained on a vast amount of text data, including conversations like this one.\n",
      "2. **Conversational Assistant**: I'm designed to provide helpful and informative responses to your questions and topics of discussion.\n",
      "3. **AI Created in 2020**: I was created using the latest advancements in artificial intelligence technology, specifically deep learning algorithms.\n",
      "\n",
      "Can you guess which statement is the lie? \n",
      "\n",
      "[Time: 3.58s]\n",
      "Bot: Statement 3, \"AI Created in 2020,\" is indeed the lie. While I've been trained on a large dataset and can provide information on a wide range of topics, my development and training data are from earlier than 2020.\n",
      "\n",
      "As for my actual creation date, I'm an evolution of various AI models and technologies that have been developed over several years. My \"birth\" date is more like March 1st, 2022, when my current architecture and capabilities were first implemented.\n",
      "\n",
      "Well done! You won this round of Two Truths and a Lie!\n",
      "\n",
      "Would you like to play again? \n",
      "\n",
      "[Time: 2.97s]\n",
      "Bot: I'll think of a word, and you try to guess it by suggesting letters. For each letter you guess correctly, I'll fill in the corresponding blanks. For each incorrect guess, I'll draw a part of the hangman's gallows. The goal is to guess the word before the gallows is complete!\n",
      "\n",
      "Here's the word: _ _ _ _ _ _ (6 letters)\n",
      "\n",
      "Guess a letter! \n",
      "\n",
      "[Time: 2.34s]\n",
      "Bot: There is one letter \"A\" in the word.\n",
      "\n",
      "_ A _ _ _ _\n",
      "\n",
      "What's your next guess?\n",
      "\n",
      "(Remember, you can guess a letter or try to solve the word if you think you know it!) \n",
      "\n",
      "[Time: 2.35s]\n",
      "Bot: There is one letter \"P\" in the word.\n",
      "\n",
      "_ A P _ _ _\n",
      "\n",
      "You're getting close! What's your next guess?\n",
      "\n",
      "(Keep going, you can do it!) \n",
      "\n",
      "[Time: 3.04s]\n",
      "Bot: **No B**: Unfortunately, there is no letter \"B\" in the word.\n",
      "\n",
      "_ A P _ _ _\n",
      "\n",
      "And...\n",
      "\n",
      "**Yes O**: There is one letter \"O\" in the word!\n",
      "\n",
      "_ A P O _ _\n",
      "\n",
      "You're really close now! What's your next guess?\n",
      "\n",
      "(Keep going, you can solve it!) \n",
      "\n",
      "[Time: 3.22s]\n",
      "Bot: So close!\n",
      "\n",
      "**No R**: Unfortunately, there is no letter \"R\" in the word.\n",
      "\n",
      "_ A P O _ _\n",
      "\n",
      "Don't worry, you're still very close! What's your next guess?\n",
      "\n",
      "(Hint: You can try to guess a letter or, if you think you know it, solve the word!) \n",
      "\n",
      "[Time: 3.50s]\n",
      "Bot: **Yes S**: There is one letter \"S\" in the word!\n",
      "\n",
      "_ A P O S _\n",
      "\n",
      "You're almost there! What's your next guess?\n",
      "\n",
      "(Hint: You can try to solve the word or guess another letter!)\n",
      "\n",
      "(By the way, you have 2 chances left before the hangman gets...well, hanged) \n",
      "\n",
      "[Time: 3.88s]\n",
      "Bot: So close!\n",
      "\n",
      "**No C**: Unfortunately, there is no letter \"C\" in the word.\n",
      "\n",
      "_ A P O S _\n",
      "\n",
      "Don't worry, you're still very close! Since you think you can solve the word, I'll give you a chance to do just that. Take another look at the letters and see if you can guess the correct word!\n",
      "\n",
      "(Hint: The word is a common, everyday term.) \n",
      "\n",
      "[Time: 4.16s]\n",
      "Bot: But unfortunately...\n",
      "\n",
      "**No E**: There is no letter \"E\" in the word.\n",
      "\n",
      "_ A P O S _\n",
      "\n",
      "You've run out of chances! Don't worry, it's okay. You played a great game!\n",
      "\n",
      "The correct answer was not a real word... I made a mistake again! \n",
      "\n",
      "Would you like to start a new game of hangman? I promise this time the word will be real and solvable! \n",
      "\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import faiss\n",
    "import ollama\n",
    "\n",
    "MODEL_NAME = \"llama3.2\"\n",
    "DB_FILE = \"mem.db\"\n",
    "INDEX_FILE = \"mem.index\"\n",
    "SHORT_TERM_TOKS = 1000\n",
    "TOP_K = 5\n",
    "\n",
    "class OllamaClient:\n",
    "    def __init__(self, model_name):\n",
    "        self.model = model_name\n",
    "\n",
    "    def chat(self, messages):\n",
    "        \"\"\"Send a messages list to the model and return the reply\"\"\"\n",
    "        start = time.time()\n",
    "        resp = ollama.chat(model=self.model, messages=messages)\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"[Time: {elapsed:.2f}s]\")\n",
    "        return resp[\"message\"][\"content\"]\n",
    "\n",
    "    def embed(self, text):\n",
    "        \"\"\"Get an embedding vector for text\"\"\"\n",
    "        resp = ollama.embed(model=self.model, input=text)\n",
    "\n",
    "        embs = resp.get(\"embeddings\")\n",
    "\n",
    "        if embs is None:\n",
    "            raise KeyError(f\"No embedding(s) in response—got keys: {list(resp.keys())}\")\n",
    "\n",
    "        # For a single-input call, unwrap the first vector\n",
    "        vec = embs[0] if isinstance(embs[0], list) else embs\n",
    "\n",
    "        return np.array(vec, dtype=\"float32\")\n",
    "\n",
    "class MemoryManager:\n",
    "    def __init__(self, dim, db_file=DB_FILE, index_file=INDEX_FILE):\n",
    "        # load or build FAISS index\n",
    "        if os.path.exists(index_file):\n",
    "            self.index = faiss.read_index(index_file)\n",
    "        else:\n",
    "            self.index = faiss.IndexFlatL2(dim)\n",
    "        self.index_file = index_file\n",
    "\n",
    "        # SQLite for storing text and metadata\n",
    "        self.conn = sqlite3.connect(db_file)\n",
    "        self._ensure_tables()\n",
    "    \n",
    "    def close(self):\n",
    "        self.conn.close()\n",
    "\n",
    "    def _ensure_tables(self):\n",
    "        self.conn.execute(\"\"\"\n",
    "          CREATE TABLE IF NOT EXISTS memories (\n",
    "            id          INTEGER PRIMARY KEY,\n",
    "            text        TEXT      NOT NULL,\n",
    "            is_summary  INTEGER   NOT NULL DEFAULT 0,\n",
    "            ts          DATETIME  DEFAULT CURRENT_TIMESTAMP\n",
    "          )\n",
    "        \"\"\")\n",
    "        self.conn.commit()\n",
    "\n",
    "    def add(self, text, vec, is_summary=False):\n",
    "        \"\"\"Add a new memory.\"\"\"\n",
    "        idx = self.index.ntotal\n",
    "        self.index.add(vec.reshape(1, -1))\n",
    "        self.conn.execute(\n",
    "          \"INSERT INTO memories (id, text, is_summary) VALUES (?, ?, ?)\",\n",
    "          (idx, text, 1 if is_summary else 0)\n",
    "        )\n",
    "        self.conn.commit()\n",
    "\n",
    "    def query(self, vec, top_k=TOP_K):\n",
    "        \"\"\"Return top_k most similar memory texts\"\"\"\n",
    "        if self.index.ntotal == 0:\n",
    "            return []\n",
    "\n",
    "        D, I = self.index.search(vec.reshape(1, -1), top_k)\n",
    "        placeholders = \",\".join(\"?\" for _ in I[0])\n",
    "        rows = self.conn.execute(\n",
    "          f\"SELECT text FROM memories WHERE id IN ({placeholders})\",\n",
    "          tuple(int(i) for i in I[0])\n",
    "        ).fetchall()\n",
    "        return [r[0] for r in rows]\n",
    "\n",
    "    def save(self):\n",
    "        faiss.write_index(self.index, self.index_file)\n",
    "\n",
    "\n",
    "def count_tokens(text):\n",
    "    \"\"\"Rough token count\"\"\"\n",
    "    return len(text.split())\n",
    "\n",
    "class ChatCLI:\n",
    "    def __init__(self, client, memory_mgr):\n",
    "        self.client = client\n",
    "        self.mem_mgr = memory_mgr\n",
    "        self.short_term = []\n",
    "        self.token_buff = 0\n",
    "    def run(self):\n",
    "        print(\"Retrieval‑Augmented ChatCLI (type 'quit' to exit)\\n\")\n",
    "        try:\n",
    "            while True:\n",
    "                prompt = input(\"You: \").strip()\n",
    "                if not prompt:\n",
    "                    continue\n",
    "                if prompt.lower() == \"quit\":\n",
    "                    print(\"Goodbye!\")\n",
    "                    break\n",
    "\n",
    "                user_vec = self.client.embed(prompt)\n",
    "                self.mem_mgr.add(prompt, user_vec, is_summary=False)\n",
    "\n",
    "                # Fetch relevant long‑term memories\n",
    "                retrieved = self.mem_mgr.query(user_vec)\n",
    "\n",
    "                #  Assemble messages for the model\n",
    "                messages = [\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
    "                ]\n",
    "                for mem in retrieved:\n",
    "                    messages.append({\"role\":\"system\", \"content\":f\"Memory: {mem}\"})\n",
    "                # include short‑term buffer\n",
    "                for role, text in self.short_term:\n",
    "                    messages.append({\"role\": role, \"content\": text})\n",
    "                # append the new user message\n",
    "                messages.append({\"role\":\"user\", \"content\": prompt})\n",
    "\n",
    "                reply = self.client.chat(messages)\n",
    "                print(\"Bot:\", reply, \"\\n\")\n",
    "\n",
    "                # Track short‑term context & token count\n",
    "                self.short_term.append((\"user\", prompt))\n",
    "                self.short_term.append((\"assistant\", reply))\n",
    "                self.token_buff += count_tokens(prompt) + count_tokens(reply)\n",
    "\n",
    "                # Store assistant reply embedding\n",
    "                bot_vec = self.client.embed(reply)\n",
    "                self.mem_mgr.add(reply, bot_vec, is_summary=False)\n",
    "\n",
    "                # If short‑term gets too big, summarize & clear\n",
    "                if self.token_buff > SHORT_TERM_TOKS:\n",
    "                    summary_prompt = (\n",
    "                        \"Summarize the following conversation in about 200 tokens:\\n\\n\"\n",
    "                        + \"\\n\".join(f\"{r}: {t}\" for r,t in self.short_term)\n",
    "                    )\n",
    "                    summary = self.client.chat([\n",
    "                        {\"role\":\"system\",\"content\":\"You are an expert summarizer.\"},\n",
    "                        {\"role\":\"user\",\"content\":summary_prompt}\n",
    "                    ])\n",
    "                    # embed & store the summary\n",
    "                    sum_vec = self.client.embed(summary)\n",
    "                    self.mem_mgr.add(summary, sum_vec, is_summary=True)\n",
    "\n",
    "                    # reset short‑term buffer\n",
    "                    self.short_term = []\n",
    "                    self.token_buff = 0\n",
    "\n",
    "        except (KeyboardInterrupt, EOFError):\n",
    "            print(\"\\nExiting\")\n",
    "            sys.exit(0)\n",
    "        finally:\n",
    "            # persist index on exit\n",
    "            self.mem_mgr.save()\n",
    "            self.mem_mgr.close()\n",
    "\n",
    "\n",
    "# Initialize client & get embed dim dynamically\n",
    "client = OllamaClient(MODEL_NAME)\n",
    "# get a test embedding to infer dimension\n",
    "test_vec = client.embed(\"hello world\")\n",
    "dim = test_vec.shape[0]\n",
    "\n",
    "# Initialize memory manager\n",
    "mem_mgr = MemoryManager(dim=dim)\n",
    "\n",
    "# Running\n",
    "cli = ChatCLI(client, mem_mgr)\n",
    "cli.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ce2d6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables: ['memories']\n",
      "[ 12][M][2025-08-16 10:41:20] It seems like we've had a bit of a loop going on here. I'm happy to chat with you again, though!\n",
      "\n",
      "Since our conversation started with your question about the fastest horse in Uma Musume (I assume that's the correct spelling), I can try to help you with that if you'd like.\n",
      "[ 11][M][2025-08-16 10:41:19] hello again\n",
      "[ 10][M][2025-08-16 10:07:34] Uma Musume Pretty Derby is a Japanese manga and anime series, and I couldn't find any definitive answer to who is the \"fastest\" horse among the characters. However, some of the main horses are known for their speed:\n",
      "\n",
      "* Takane\n",
      "* Sankichi\n",
      "* Umehito\n",
      "[  9][M][2025-08-16 10:07:33] Who is the fastest horse in uma musame\n",
      "[  8][M][2025-08-16 10:07:08] Who is the strongest transformer\n",
      "[  7][M][2025-08-16 10:06:39] A question that has sparked debate among Gundam fans for decades! The \"strongest\" Gundam can be subjective and often depends on the specific scenario, tactics, and piloting skills. However, I'll provide you with an analysis of some of the most powerful Gundams in the franchise's history.\n",
      "\n",
      "**The Contenders:**\n",
      "\n",
      "1. **Gundam X (PGX-001)**: A mobile suit designed by Dr. Bright Nozua, the Gundam X is a highly advanced, experimental mobile suit that features a unique hybrid propulsion system and advanced combat capabilities.\n",
      "2. **Zeta Gundam (MSZ-006 Zeta Gundam)**: Piloted by Kamille Bidan, the Zeta Gundam is an upgraded version of the RX-78-2 Gundam, boasting enhanced mobility, firepower, and armor plating.\n",
      "3. **Strike Gundam (MSZ-006E Strike Gundam)**: An improved variant of the Zeta Gundam, the Strike Gundam features advanced armor plating, increased speed, and improved maneuverability.\n",
      "4. **Gundam 00 Raiser (Gundam 00)**: A highly advanced mobile suit piloted by Setsuna F. Seiei, the Raiser boasts incredible speed, agility, and combat capabilities, including a powerful beam rifle and advanced shield system.\n",
      "5. **Char's Zaku II (MSZ-006A Char's Zaku II)**: While not as flashy as some of the other options, Char's Zaku II is an extremely durable and versatile mobile suit that can withstand significant damage before being rendered inoperable.\n",
      "\n",
      "**The Winner:**\n",
      "\n",
      "After careful consideration, I would argue that the **Gundam X (PGX-001)** is the strongest Gundam. Here's why:\n",
      "\n",
      "* Unique Hybrid Propulsion System: The Gundam X features a revolutionary propulsion system that combines conventional and electromagnetic principles, allowing for incredible speed and maneuverability.\n",
      "* Advanced Combat Capabilities: The mobile suit boasts an impressive array of advanced combat systems, including dual beam sabers, point-defense systems, and an advanced ECM suite.\n",
      "* Enhanced Armor Plating: The Gundam X's armor plating is significantly more advanced than most mobile suits, providing enhanced protection against anti-missile systems and enemy attacks.\n",
      "\n",
      "**Honorable Mention:**\n",
      "\n",
      "While not as powerful as the Gundam X, the **Zeta Gundam (MSZ-006 Zeta Gundam)** is an incredibly formidable opponent. Its combination of speed, firepower, and armor plating make it a force to be reckoned with on the battlefield.\n",
      "\n",
      "Remember that the \"strongest\" Gundam can depend on the specific situation and pilot. A skilled pilot operating a less powerful mobile suit may still achieve victory through cunning tactics and strategic thinking.\n",
      "\n",
      "Now, let's get into some debate – what do you think? Do you agree with my assessment of the strongest Gundam, or do you have another contender in mind?\n",
      "[  6][M][2025-08-16 10:06:26] What is the strongest gundam? Explain in detail/\n",
      "[  5][M][2025-08-16 09:53:11] It looks like you're ready to wrap things up! It was nice chatting with you, even if it was brief. If you ever need anything or just want to say hello again, feel free to come back anytime. Have a great day!\n",
      "[  4][M][2025-08-16 09:53:10] exit\n",
      "[  3][M][2025-08-16 09:53:05] It seems like we've established the classic \"hello\" conversation starter! Would you like to break the ice with a question, share something on your mind, or just chat for a bit? I'm here to listen and help in any way I can.\n",
      "[  2][M][2025-08-16 09:53:03] hello\n",
      "[  1][M][2025-07-26 09:40:23] It's nice to meet you. How can I assist you today? Do you have any questions or topics you'd like to discuss?\n",
      "[  0][M][2025-07-26 09:40:22] hello there\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Connect to your database file\n",
    "conn = sqlite3.connect('mem.db')\n",
    "\n",
    "# List ALL tables\n",
    "cursor = conn.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = [row[0] for row in cursor.fetchall()]\n",
    "print(\"Tables:\", tables)\n",
    "\n",
    "# Query the memories table\n",
    "cursor = conn.execute(\"SELECT id, is_summary, ts, text FROM memories ORDER BY ts DESC;\")\n",
    "for id, is_summary, ts, text in cursor.fetchall():\n",
    "    flag = \"S\" if is_summary else \"M\" # S = summary, M = memory\n",
    "    print(f\"[{id:3d}][{flag}][{ts}] {text}\")\n",
    "\n",
    "# Close when done\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a2b6fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d75501b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
